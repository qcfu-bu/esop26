We implement a prototype compiler for \TLLC{}. The main components of the compiler
are written in OCaml while a minimalistic runtime library is implemented in C.
The compiler takes \TLLC{} source files as input and generates safe C code which
can be further compiled into executable binaries on POSIX compliant systems.
In this section, we give an overview of the inference, linearity checking
and optimization phases of the compiler.

\paragraph{\textbf{Inference}}
To reduce code duplication and type annotation burden, we implement two forms of inference: 
(1) automatic instantiation of \emph{sort-polymorphic schemes} similarly to the TLL compiler and 
(2) elaboration of inferred arguments.
Consider the identity function below:
\begin{align*}
  \Def\ \textsf{id}\flq{s}\frq\ \%\!\{ A : \textsf{Type}\flq{s}\frq\}\ (x : A) : A := x
\end{align*}
This function is a sort-polymorphic scheme as it is parameterized over sort variable $s$.
Depending on the universe of $A$, sort $s$ can be instantiated to either $\Ln$ for linear types
or $\Un$ for unrestricted types. This eliminates the need to define two separate identity functions
for linear and unrestricted types. The type $A$ here is marked by $\%$ to indicate that it is an
inferred argument. Suppose $\textsf{id}$ is applied to a natural number $42$, the compiler creates
two metavariables $\hat{s}$ and $\hat{\alpha}$ to represent the elided sort and type arguments respectively.
Type inference produces the following constraints:
\begin{align*}
  \textsf{id}\ 42 
  \ \ 
  \xRightarrow{\text{desugar}} 
  \ \ 
  \appI{\textsf{id}\flq{\hat{s}}\frq}{\hat{\alpha}}\ 42
  \ \ 
  \xRightarrow{\text{infer}} 
  \ \ 
  \begin{cases}
    \hat{s} = \Un \\
    \hat{\alpha} = \textsf{Nat}
  \end{cases}
  \!\!
  \xRightarrow{\text{mono}} 
  \ \ 
  \appI{\textsf{id}\flq{\Un}\frq}{\textsf{Nat}}\ 42
\end{align*}
Once the constraints are solved through unification~\cite{abel11}, the metavariables are
replaced by their solutions. The monomorphized code is then passed to the next phase for
linearity checking.


\paragraph{\textbf{Linearity Checking}}
During the inference phase, the usage of linear variables is not tracked. The
type checking algorithm essentially treats \TLLC{} as a fully structural type
system. It is only after all sort-polymorphic schemes and inferred arguments are
instantiated that the linearity checking begins. A substructural type checking
algorithm is applied to determine if the elaborated program compiles with the actual
typing rules of \TLLC{}. We adopt this two-phase approach to simplify the linearity
checking algorithm. Although sort-polymorphism greatly reduces code duplication from
the user's perspective, it also obfuscates the classification of types into linear
and unrestricted ones. Thus, it is much easier to check linearity after monomorphization.

To support dependent pattern matching, we implement a variation of 
Cockx's algorithm~\cite{cockx18} to type check \Match{}-expressions and elaborate them
into well-formed case trees. Cockx's algorithm forms the basis of Agda's~\cite{agda}
pattern matching mechanism. Several extensions are made to the original algorithm to
account for pattern matching on linear inductive types and ghost terms. Our modified
algorithm is able to correctly track resource usage in subtle cases such as nested
patterns involving linear inductive types. We plan to present the details of our
algorithm in a future publication.

\paragraph{\textbf{Optimization}}
Once linearity checking is complete, ghost terms are erased in a type directed
manner.  The intermediate representation (IR) obtained from erasure carries
metadata that mark the linearity of certain critical expressions. For example,
metadata is attached to \Match{}-expressions to indicate whether the scrutinee
is linear or unrestricted. This information is used to guide further
optimizations for improving runtime efficiency.

One of the optimizations performed is constructor unboxing. The layouts of inductive type
constructors are analyzed to determine if the inductive type is suitable for unboxing.
For example, consider the singleton type defined as follows:
\begin{align*}
  \Inductive\ \textsf{sing}\flq{s}\frq\ \%\!\{A : \textsf{Type}\flq{s}\frq\}\ (x : A) := 
  \textsf{Just} : \forall (x : A) \rightarrow \textsf{sing}\ x
\end{align*}
Here, \textsf{Just} is the only constructor of type \textsf{sing}. This means that
pattern matching on a value of type \textsf{sing} is redundant as there is only one possible case.
Expressions of the form $\textsf{Just}\ m$ are unboxed to $m$ to reduce the number of indirections
at runtime. In general, an inductive type can be unboxed if it has a single constructor and
the constructor has a single non-ghost field.

To reduce the time spent on allocating and deallocating heap objects, we utilize
in-place updates for linear values. This optimization is similar to recent works on
function in-place programming~\cite{lorenzen23,perceus} where allocated heap memory
is reused instead of being garbage collected. Unlike these works which utilize reference
counting to dynamically check the viability of an in-place update, the metadata in our 
IR is sufficient to statically determine if an in-place optimization is safe.