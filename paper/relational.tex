Earlier in the introduction section, we showed a sketch of how dependent session types
can be used for certified concurrent programming through the example of a concurrent queue.
In this section, we provide a detailed account of how we can use dependent session types
to construct a generic map-reduce system. Similarly to the queue example, we will verify
the correctness of the map-reduce system by relating it to sequential operations on trees.

\subsection{Construction of Map-Reduce}
Map-reduce is a commonly used programming model for processing large data sets in parallel.
Initially, map-reduce creates a tree of concurrently executing workers as illustrated in
\Cref{fig:map-reduce}. The client partitions the data into smaller chunks and sends them to
the leaf workers of the tree. Next, each leaf worker applies a user-specified
function $f$ to each of its received data chunks and sends the results to its parent worker.
When an internal worker receives results from its children, it combines the results using another
user-specified binary function $g$. This procedure continues until the root worker computes
the final result and sends it back to the client. Due to the fact that workers without
data dependencies can operate concurrently, the overall system can achieve significantly better
performance than sequential implementations of the same operations.
\vspace{-0.3em}
\begin{figure}[H]
\begin{tikzpicture}[
  treenode/.style = {shape=rectangle, rounded corners,
                     draw, align=center,
                     fill=blue!20},
  client/.style   = {shape=rectangle, draw=red!60, fill=red!5},
  root/.style     = {circle,draw},
  env/.style      = {treenode},
  dummy/.style    = {circle,draw,fill=black!2},
  grow = right,
  edge from parent/.style = {draw, -latex},
  sloped,
  level distance=2cm,
  level 1/.style={sibling distance=4em},
  level 2/.style={sibling distance=2em}
]
  \node [client]            (c0) {client};
  \node [root, right= 2cm of c0] (t0) {}
    child { node [dummy] {}
      child { node [env] {$a_3$} }
      child { node [env] {$a_2$} }
    }
    child { node [dummy] {}
      child { node [env] {$a_1$} }
      child { node [env] {$a_0$} }
    };
\draw[-latex,transform canvas={yshift=+0.5ex}] (c0.east) -- (t0.west) node [midway, above] {data};
\draw[latex-,transform canvas={yshift=-0.5ex}] (c0.east) -- (t0.west) node [midway, below] {result};
\end{tikzpicture}
\vspace{-0.8em}
\caption{Tree Diagram of Map-Reduce}
\label{fig:map-reduce}
\end{figure}
\vspace{-0.8em}

The first step in constructing the map-reduce system is to build a model of our desired
computation in a sequential setting. For this purpose, we define a simple binary tree
inductive type:

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.25em}
\begin{alignat*}{4}
  &\Inductive\ \textsf{tree}\ (A : \Un) :=\
    \textsf{Leaf} : A \rightarrow \textsf{tree}(A) \mid\
    \textsf{Node} : \textsf{tree}(A) \rightarrow \textsf{tree}(A) \rightarrow \textsf{tree}(A)
  \\[0.4em]
  &\begin{alignedat}{4}
    &\Def\ \textsf{map} : \forall \{A\ B : \Un\}\ (f : A \rightarrow B) \rightarrow \textsf{tree}(A) \rightarrow \textsf{tree}(B) \\
    &\quad\mid\ \textsf{Leaf}\ x \Rightarrow \textsf{Leaf}\ (f\ x) \\
    &\quad\mid\ \textsf{Node}\ l\ r \Rightarrow \textsf{Node}\ (\textsf{map}\ f\ l) (\textsf{map}\ f\ r)
  \end{alignedat}
  \\[0.4em]
  &\begin{alignedat}{4}
    &\Def\ \textsf{reduce} : \forall \{A\ B : \Un\}\ (f : A \rightarrow B)\ (g : B \rightarrow B \rightarrow B) \rightarrow \textsf{tree}(A) \rightarrow B \\
    &\quad\mid\ \textsf{Leaf}\ x \Rightarrow f\ x \\
    &\quad\mid\ \textsf{Node}\ l\ r \Rightarrow g\ (\textsf{reduce}\ f\ g\ l)\ (\textsf{reduce}\ f\ g\ r)
  \end{alignedat}
\end{alignat*}
\endgroup
In this definition, the type \Un{} of $A$ is the universe of \emph{unbound}
(i.e. non-linear) types in \TLLC{}. So \textsf{tree} is parameterized by $A$
which represents the type of data stored at the leaf nodes. The \emph{sequential}
\textsf{map} and \textsf{reduce} functions for \textsf{tree} are all defined in a standard way.

To construct the concurrent map-reduce system, we must define the kinds of operations
that can be performed. This requires the protocol of map-reduce to branch depending on
what operation the client requests to perform. Unlike many prior
session type systems~\cite{caires10,das20} which provide built-in constructs
(e.g. $\oplus$ and $\&$) for internal and external choice, we implement branching
protocols using just dependent protocols and type-level pattern matching on sent or received
messages. For our map-reduce system, we define the kinds of operations that can be performed
through the inductive type \textsf{opr}:

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.25em}
\begin{align*}
  \Inductive\ \textsf{opr}(A : \Un) :=\ &\textsf{Map}   : \forall \{B : \Un\}\ (f : A \rightarrow B) \rightarrow \textsf{opr}(A) \\
  \mid\ &\textsf{Reduce}: \forall \{B : \Un\}\ (f : A \rightarrow B)\ (g : B \rightarrow B \rightarrow B) \rightarrow \textsf{opr}(A) \\
  \mid\ &\textsf{Free}  : \textsf{opr}(A)
\end{align*}
\endgroup

The \textsf{opr} type has three constructors:
\begin{itemize}
  \item $\textsf{Map}\ f$ represents a map operation that applies the function
        $f : A \rightarrow B$ to each element of type $A$ and produces results of type $B$.
  \item $\textsf{Reduce}\ f\ g$ represents a reduce operation that first
        applies the function $f : A \rightarrow B$ to each element of type $A$ and then
        combines the results using the binary function $g : B \rightarrow B \rightarrow B$.
  \item $\textsf{Free}$ is the command that terminates the concurrent tree.
\end{itemize}

We are now ready to define the session type for the map-reduce protocol.
The following \textsf{treeP} protocol is used to describe the interactions between nodes
in the map-reduce tree.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.25em}
\begin{alignat*}{4}
  &\Def\ \textsf{treeP}\ (A : \Un)\ (t : \textsf{tree}\ A) :=\ ?(o : \textsf{opr}\ A).\\
  &\quad
    \begin{alignedat}{4}
      \Match\ o\ \With&\ \textsf{Map}\ \_\ f \Rightarrow\ \textsf{treeP}\ B\ (\textsf{map}\ f\ t) \\
                  \mid&\ \textsf{Reduce}\ \_\ f\ g \Rightarrow\ !(\textsf{sing}\ (\textsf{reduce}\ f\ g\ t)).\ \textsf{treeP}\ t \\
                  \mid&\ \textsf{Free} \Rightarrow \End
    \end{alignedat}
\end{alignat*}
\endgroup
For each node $n$ in the concurrent tree, it will be providing a channel of type
$\CH{\textsf{treeP}\ A\ t}$ to its parent. The parameter $t$ of type
$\textsf{tree}\ A$ represents the shape of the sub-tree rooted at $n$. The
\textsf{treeP} protocol states node $n$ will receive a message $o$ of type
$\textsf{opr}\ A$ from its parent.  The protocol then branches, via type-level
pattern matching on $o$, into three cases. If $o$ is of the form
$\textsf{Map}\ f$, then $n$ will continue the protocol as
$\textsf{treeP}\ B\ (\textsf{map}\ f\ t)$. Notice that the type parameter of
\textsf{treeP} has changed from $A$ to $B$ to reflect the fact that the data
stored at the leaves of the sub-tree has been transformed from type $A$ to type
$B$. Furthermore, the shape of the sub-tree has also changed from $t$ to
$\textsf{map}\ f\ t$. In the second case where $o$ is of the form
$\textsf{Reduce}\ f\ g$, $n$ will first send the result of type
$\textsf{sing}\ (\textsf{reduce}\ f\ g\ t)$ to its parent. The type
$\textsf{sing}\ x$ is the \emph{singleton type} whose sole inhabitant is the
element $x$. After sending the result, $n$ will continue the protocol as
$\textsf{treeP}\ t$, i.e. remains unchanged. Finally, $n$ will terminate
the protocol when $o$ is $\textsf{Free}$.

Using the \textsf{treeP} protocol, we can now implement the worker processes
that run at each node of the concurrent tree. The implementation of a leaf worker
is shown below. We have elided uninteresting technical details regarding dependent
pattern matching.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.25em}
\begin{align*}
  &\Def\ \textsf{leafWorker}\ \{A : \Un\}\ (x : A)\ (c : \CH{\textsf{treeP}\ A\ (\textsf{Leaf}\ x)}) : \CM{\textsf{unit}} := \\
  &\quad\Let\ \langle{o, c}\rangle := \Recv\ c\ \In \\
  &\quad
    \begin{alignedat}{4}
      &\Match\ o\ \With\\
      &\mid \textsf{Map} \Rightarrow \textsf{leafWorker}\ \{B\}\ (f\ x)\ c \\
      &\mid \textsf{Reduce} \Rightarrow \Let\ c \Leftarrow \Send\ c\ (\textsf{just}\ (f\ x))\ \In\ \textsf{leafWorker}\ \{A\}\ x\ c  \\
      &\mid \textsf{Free} \Rightarrow \Close(c)
    \end{alignedat}
\end{align*}
\endgroup
The \textsf{leafWorker} function takes two non-ghost arguments: a data element
$x$ of type $A$ and a channel $c$ of type
$\CH{\textsf{treeP}\ A\ (\textsf{Leaf}\ x)}$. Through this channel $c$, the leaf
worker will receive requests from its parent and provide responses accordingly.
For instance, when the leaf worker receives a $\textsf{Map}\ f$ request, it will
apply $f: A \rightarrow B$ to its data element $x$ and continue as a leaf worker
with the new data element $f x$. In this case, the type parameter of
\textsf{leafWorker} has changed from $A$ to $B$ to reflect the transformation of
the data element.

To represent internal node workers we implement the following \textsf{nodeWorker}
function. This function takes (non-ghost) channels $c_l$ and $c_r$ of
types $\HC{\textsf{treeP}\ A\ l}$ and $\HC{\textsf{treeP}\ A\ r}$ for
communicating with its left and right children. Notice that the types of these
channels are indexed by ghost values $l$ and $r$ of type $\textsf{tree}\ A$
which represent the shapes of the concurrent sub-trees providing $c_l$ and
$c_r$. The \textsf{nodeWorker} communicates with its parent through the channel
$c$ whose type is indexed by the ghost value $\textsf{Node}\ l\ r$.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.25em}
\begin{align*}
  &\Def\ \textsf{nodeWorker}\ \{A : \Un\}\ \{l\ r : \textsf{tree}\ A\}\\
  &\qquad(c_l : \HC{\textsf{treeP}\ A\ l})\ (c_r : \HC{\textsf{treeP}\ A\ r})\ (c : \CH{\textsf{treeP}\ A\ (\textsf{Node}\ l\ r)}) : \CM{\textsf{unit}} := \\
  &\quad\Let\ \langle{o, c}\rangle := \Recv\ c\ \In \\
  &\quad
    \begin{alignedat}{4}
      &\Match\ o\ \With\\
      &\mid \textsf{Map}\ \_\ f \Rightarrow \\
      &\quad\Let\ c_l \Leftarrow \Send\ c_l\ (\textsf{Map}\ f)\ \In \\
      &\quad\Let\ c_r \Leftarrow \Send\ c_r\ (\textsf{Map}\ f)\ \In \\
      &\quad\Let\ c \Leftarrow \Send\ c\ (\textsf{just}\ \textsf{unit})\ \In \\
      &\quad\textsf{nodeWorker}\ \{B\}\ \{(\textsf{map}\ f\ l)\ (\textsf{map}\ f\ r)\}\ c_l\ c_r\ c \\
      &\mid \textsf{Reduce}\ \_\ f\ g \Rightarrow \\
      &\quad\Let\ c_l \Leftarrow \Send\ c_l\ (\textsf{Reduce}\ f\ g)\ \In \\
      &\quad\Let\ c_r \Leftarrow \Send\ c_r\ (\textsf{Reduce}\ f\ g)\ \In \\
      &\quad\Let\ \langle{\textsf{just}\ v_l, c_l}\rangle \Leftarrow \Recv\ c_l\ \In \\
      &\quad\Let\ \langle{\textsf{just}\ v_r, c_r}\rangle \Leftarrow \Recv\ c_r\ \In \\
      &\quad\Let\ c \Leftarrow \Send\ c\ (\textsf{just}\ (g\ v_l\ v_r))\ \In \\
      &\quad\textsf{nodeWorker}\ \{A\}\ \{l\ r\}\ c_l\ c_r\ c \\
      &\mid \textsf{Free} \Rightarrow \\
      &\quad\Let\ c_l \Leftarrow \Send\ c_l\ \textsf{Free}\ \In \\
      &\quad\Let\ c_r \Leftarrow \Send\ c_r\ \textsf{Free}\ \In \\
      &\quad\Wait(c_l); \Wait(c_r); \Close(c)
    \end{alignedat}
\end{align*}
\endgroup
Given the signature of \textsf{nodeWorker} and the definition of
the \textsf{treeP} protocol, it is not hard to see that the implementation of
\textsf{nodeWorker} is constrained to function exactly as intended. For instance,
in the case where \textsf{nodeWorker} receives a $\textsf{Map}\ f$ request from
its parent, the type of $c$ becomes $\CH{\textsf{treeP}\ B\ (\textsf{map}\ f\ (\textsf{Node}\ l\ r))}$
which simplifies to $\CH{\textsf{treeP}\ B\ (\textsf{Node}\ (\textsf{map}\ f\ l)\ (\textsf{map}\ f\ r))}$.
The shapes of the left and right sub-trees after the map operation need to become
$\textsf{map}\ f\ l$ and $\textsf{map}\ f\ r$ respectively. In other words, the
type of $c$ forces the \textsf{nodeWorker} process to recursively send the
$\textsf{Map}\ f$ request to both of its children to transform them into
sub-trees of type $\HC{\textsf{treeP}\ B\ (\textsf{map}\ f\ l)}$ and
$\HC{\textsf{treeP}\ B\ (\textsf{map}\ f\ r)}$.

\subsection{A Certified Interface for Map-Reduce}
Now that we have defined both leaf and internal node workers, we can wrap them
up into a more convenient interface as presented below.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.2em}
\begin{align*}
  &\Type\ \textsf{cTree}\ (A : \Un)\ (t : \textsf{tree}\ A) := \CM{\HC{\textsf{treeP}\ t}}
  \\[0.5em]
  &\Def\ \textsf{cLeaf}\ \{A : \Un\}\ (x : A) : \textsf{cTree}\ A\ (\textsf{Leaf}\ x) := \\
  &\quad\Fork(c : \CH{\textsf{treeP}\ A\ (\textsf{Leaf}\ x)})\ \With\ \textsf{leafWorker}\ x\ c
  \\[0.5em]
  &\Def\ \textsf{cNode}\ \{A : \Un\} \{l\ r : \textsf{tree}\ A\}\ (c_l : \textsf{cTree}\ A\ l)\ (c_r : \textsf{cTree}\ A\ r) : \textsf{cTree}\ (\textsf{Node}\ l\ r) := \\
  &\quad\Let\ c_l \Leftarrow c_l\ \In \\
  &\quad\Let\ c_r \Leftarrow c_r\ \In \\
  &\quad\Fork(c : \CH{\textsf{treeP}\ A\ (\textsf{Node}\ l\ r)})\ \With\ \textsf{nodeWorker}\ c_l\ c_r\ c
\end{align*}
\endgroup
The type alias \textsf{cTree} is defined to aid in the readability of the interface.
The wrapper functions \textsf{cLeaf} and \textsf{cNode} respectively create leaf
and internal node workers. This is accomplished by \emph{forking} a new process using
the \Fork{} construct of the concurrency monad. In particular, when given some a channel type
$\CH{P}$, the \Fork{} construct will create a new channel and give one end of it to the caller
at type $\HC{P}$ and spawn a new process that runs the worker with the other end of the channel
at type $\CH{P}$. The duality of the channels types allows the caller and the worker to communicate.
Using these wrapper functions, one can construct a concurrent tree in virtually the same way
as one would construct a sequential tree. For example, the following code constructs a
concurrent tree with four leaf nodes containing integers $0, 1, 2$ and
$3$ respectively.
\begin{align*}
  \textsf{cNode}\ (\textsf{cNode}\ (\textsf{cLeaf}\ 0)\ (\textsf{cLeaf}\ 1))\ (\textsf{cNode}\ (\textsf{cLeaf}\ 2)\ (\textsf{cLeaf}\ 3))
\end{align*}
The type of this expression is rather verbose to write manually as it contains the full shape
of the concurrent tree. This is not a problem in practice as \emph{constant} type arguments
(such as the tree shapes here) can almost always be inferred automatically by the type checker.

Finally, we implement the \textsf{cMap} and \textsf{cReduce} functions that provide the
map and reduce operations on concurrent trees. These functions are implemented by
simply sending the appropriate requests to the root worker of the concurrent tree.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.2em}
\begin{align*}
  &\Def\ \textsf{cMap}\ \{A\ B : \Un\}\ \{t : \textsf{tree}\ A\}\ (f : A \rightarrow B)\ (c : \textsf{cTree}\ A\ t) : \textsf{cTree}\ B\ (\textsf{map}\ f\ t) := \\
  &\quad\Let\ c \Leftarrow c\ \In \\
  &\quad\Let\ c \Leftarrow \Send\ c\ (\textsf{Map}\ f)\ \In \\
  &\quad\Return\ c
  \\[0.5em]
  &\Def\ \textsf{cReduce}\ \{A\ B : \Un\}\ \{t : \textsf{tree}\ A\}\ (f : A \rightarrow B)\ (g : B \rightarrow B \rightarrow B)\ (c : \textsf{cTree}\ A\ t) :\\
  &\qquad\CM{\textsf{sing}\ (\textsf{reduce}\ f\ g\ t) \otimes \textsf{cTree}\ A\ t} := \\
  &\quad\Let\ c \Leftarrow c\ \In \\
  &\quad\Let\ c \Leftarrow \Send\ c\ (\textsf{Reduce}\ f\ g)\ \In \\
  &\quad\Let\ \langle{v, c}\rangle \Leftarrow \Recv\ c \In \\
  &\quad\Return\ \langle{v, \Return\ c}\rangle
\end{align*}
\endgroup
From the type signature of \textsf{cMap}, we can see that it takes a function
$f$ and a concurrent tree of type $\textsf{cTree A\ t}$ and
returns a new concurrent tree of type $\textsf{cTree B\ (\textsf{map}\ f\ t)}$.
In other words, the type of \textsf{cMap} guarantees that the shape of the
concurrent tree is transformed in the same way as its sequential tree model under the
\textsf{map} function. Similarly, the \textsf{cReduce} takes a concurrent tree of type
$\textsf{cTree}\ A\ t$ and returns a
(linear) pair consisting of the result of type $\textsf{sing}\ (\textsf{reduce}\ f\ g\ t)$,
and the original concurrent tree. The correctness of \textsf{cReduce} is guaranteed
by the singleton type of its result: reducing a concurrent tree results in the same
value as reducing its sequential tree model.

\subsection{Concurrent Mergesort via Map-Reduce}
By properly instantiating the map-reduce interface defined previously, we can implement
more complex concurrent algorithms. Moreover, dependent session types allows us to easily 
verify the correctness of these derived concurrent algorithms relationally through their 
sequential models. As an extended example, we implement a concurrent version of the mergesort 
algorithm using the map-reduce interface and verify its correctness.

We define sequential \textsf{msort}, as a model of our concurrent implementation,
in the usual way using \textsf{split} and \textsf{merge} functions.
We will not go into further details regarding the well-founded recursion
of \textsf{msort} or the correctness of sorting as these are textbook results~\cite{cpdt}.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.2em}
\begin{align*}
  &\Def\ \textsf{split}\ (xs : \textsf{list}\ \textsf{int}) : \textsf{list}\ \textsf{int} \otimes \textsf{list}\ \textsf{int} := ... \\
  &\Def\ \textsf{merge}\ (xs\ ys : \textsf{list}\ \textsf{int}) : \textsf{list}\ \textsf{int} := ...
  \\[0.5em]
  &\Def\ \textsf{msort}\ (xs : \textsf{list}\ \textsf{int}) : \textsf{list}\ \textsf{int} := \Match\ xs\ \With \\
  &\quad\mid\ \textsf{nil} \Rightarrow \textsf{nil} \\
  &\quad\mid\ x :: \textsf{nil} \Rightarrow x :: \textsf{nil} \\
  &\quad\mid\ zs \Rightarrow \Let\ \langle{xs, ys}\rangle := \textsf{split}\ zs\ \In\ \textsf{merge}\ (\textsf{msort}\ xs)\ (\textsf{msort}\ ys)
\end{align*}
\endgroup

Generally, to implement an algorithm using the map-reduce paradigm, one must first 
decompose the algorithm and data into a form that is amenable to parallelization. 
For mergesort, the input list can be recursively split into smaller sub-lists
which can be processed in parallel. To make this decomposition \emph{explicit},
we define the following \textsf{splittingTree} function that constructs a binary tree
representation of how the input list is split by the mergesort algorithm.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.2em}
\begin{align*}
  &\Def\ \textsf{splittingTree}\ (xs : \textsf{list}\ \textsf{int}) : \textsf{tree}\ (\textsf{list}\ \textsf{int}) := \Match\ xs\ \With \\
  &\quad\mid\ \textsf{nil} \Rightarrow \textsf{Leaf}\ \textsf{nil} \\
  &\quad\mid\ x :: \textsf{nil} \Rightarrow \textsf{Leaf}\ (x :: \textsf{nil}) \\
  &\quad\mid\ zs \Rightarrow \Let\ \langle{xs, ys}\rangle := \textsf{split}\ zs\ \In\ \textsf{Node}\ (\textsf{splittingTree}\ xs)\ (\textsf{splittingTree}\ ys)
\end{align*}
\endgroup

Given a list of integers $xs$, we need to construct a concurrent representation of its 
splitting tree with type $\textsf{cTree}\ (\textsf{list}\ \textsf{int})\ (\textsf{splittingTree}\ xs)$.
While it is tempting to directly convert the result of \textsf{splittingTree} into a concurrent tree
by recursively replacing \textsf{Leaf} with \textsf{cLeaf} and \textsf{Node} with \textsf{cNode},
such an approach would require traversing both the input list (to construct the splitting tree) 
and then traversing the resulting tree (to convert it into a concurrent tree). This would lead to a 
bottleneck in the performance of the overall algorithm as the inputs would need to be traversed 
sequentially before any parallelism can be exploited. Instead, we define the following function
\textsf{splittingCTree} that constructs the concurrent splitting tree in a concurrent manner.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.2em}
\begin{align*}
  &\Def\ \textsf{splittingCTree}\ (xs : \textsf{list}\ \textsf{int}) : 
      \CH{!(\textsf{cTree}\ (\textsf{list}\ \textsf{int})\ (\textsf{splittingTree}\ xs)).\ \End} \rightarrow \CM{\textsf{unit}} := \\
  &\quad\Match\ xs\ \With \\
  &\quad\mid\ \textsf{nil} \Rightarrow 
    \Let\ c \Leftarrow \Send\ c\ (\textsf{cLeaf}\ \textsf{nil})\ \In\ \Close(c);\ \Return\ () \\
  &\quad\mid\ x :: \textsf{nil} \Rightarrow 
    \Let\ c \Leftarrow \Send\ c\ (\textsf{cLeaf}\ (x :: \textsf{nil}))\ \In\ \Close(c);\ \Return\ () \\
  &\quad\mid\ zs \Rightarrow \\
  &\qquad\Let\ \langle{xs, ys}\rangle := \textsf{split}\ zs\ \In \\
  &\qquad\Let\ c_l \Leftarrow \Fork(c)\ \With\ \textsf{splittingCTree}\ xs\ c\ \In \\
  &\qquad\Let\ c_r \Leftarrow \Fork(c)\ \With\ \textsf{splittingCTree}\ ys\ c\ \In \\
  &\qquad ...
\end{align*}
\endgroup
The \textsf{splittingCTree} function takes an additional channel argument $c$ which is used to
send back the constructed concurrent tree to its caller. This small change allows the
recursive case to fork two new processes to construct the left and right sub-trees
concurrently. After both sub-trees have been constructed, the parent process can then
combine them into a single concurrent tree using \textsf{cNode} and send it back
to its caller. The complete implementation of \textsf{splittingCTree} can be found in the
supplementary materials but is shortened here for brevity.

Now that we have constructed a concurrent splitting tree of our input list, we can
apply the \textsf{cReduce} operation instantiated with $f := \lambda(x). x$
and $g := \textsf{merge}$ to perform merging in parallel.
This gives us an output of type
\begin{align*}
  \CM{\textsf{sing}\ (\textsf{reduce}\ (\lambda(x). x)\ \textsf{merge}\ (\textsf{splittingTree}\ xs)) \otimes \textsf{cTree}\ (\textsf{list}\ \textsf{int})\ (\textsf{splittingTree}\ xs)} 
\end{align*}
Note that the singleton value 
$\textsf{sing}\ (\textsf{reduce}\ (\lambda(x). x)\ \textsf{merge}\ (\textsf{splittingTree}\ xs))$
returned by the monad \emph{relationally} describes this series of concurrent computations using just 
sequential operations. This allows us to easily verify the correctness of our concurrent mergesort
implementation by proving the following \emph{theorem} (in the internal logic of TLL) which states that 
reducing the splitting tree is equivalent to performing mergesort on the original input list.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.2em}
\begin{align*}
  &\Theorem\ \textsf{reduceSplittingTree} : \\
  &\quad\forall (xs : \textsf{list}\ \textsf{int}).\ \textsf{reduce}\ (\lambda(x). x)\ \textsf{merge}\ (\textsf{splittingTree}\ xs) = \textsf{msort}\ xs
\end{align*}
\endgroup
Using this theorem, we can rewrite the singleton value returned by \textsf{cReduce} to
$\textsf{sing}\ (\textsf{msort}\ xs)$. In other words, the result of our concurrent
mergesort implementation is guaranteed to be exactly the same as that of the sequential
mergesort algorithm, thus completing our verification.

The full pipeline of concurrent mergesort is given in the following \textsf{cMSort} function.

\vspace{-1em}
\begingroup
\small
\addtolength{\jot}{-0.2em}
\begin{align*}
  &\Def\ \textsf{cMSort}\ (xs : \textsf{list}\ \textsf{int}) : \CM{\textsf{sing}\ (\textsf{msort}\ xs)} := \\
  &\quad\Let\ c \Leftarrow \Fork(c)\ \With\ \textsf{splittingCTree}\ xs\ c\ \In \\ 
  &\quad\Let\ \langle{\textit{ctree}, c}\rangle \Leftarrow \Recv\ c\ \In\ \Wait\ c; \\
  &\quad\Let\ \langle{v, \textit{ctree}}\rangle \Leftarrow \textsf{cReduce}\ (\lambda(x). x)\ \textsf{merge}\ \textit{ctree}\ \In \\
  &\quad\Let\ \textit{ctree} \Leftarrow \Send\ \textit{ctree}\ \textsf{Free}\ \In\ \Wait\ \textit{ctree}; \\
  &\quad\Return\ (\Rewrite[\textsf{reduceSplittingTree}]\ v)
\end{align*}
\endgroup

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "main"
%%% End:
